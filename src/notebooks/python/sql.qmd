---
title: "Importing Data from SQL in Python"
subtitle: "Interacting with SQL Databases & Accessing SQL Data in Python Using PYODBC & SQLAlchemy"
author: "Paul Johnson"
date: today
execute:
  eval: false
---

One of the first tasks you will need to do with any analysis is loading in the data. While you may have data from a variety of sources, the most common will be in a SQL database. Here we will cover how to access a SQL database and extract data in Python.

**NOTE: Unlike other notebooks, this notebook won't run and give you outputs because it does not contain the SQL server connection and database details that it needs to pull data. You need to fill in those blanks if you want to run the code below.**

## Libraries

You need the following Python libraries to run the code in this notebook:

- pyodbc - accessing ODBC databases
- sqlalchemy - establishing a connection and interacts with pandas
- pandas - storing, manipulating, and exporting dataframes

```{python}
#| label: setup

import pyodbc
import sqlalchemy as sa
import pandas as pd

from sqlalchemy import create_engine

```

## Establish SQL Connection

In order to run a SQL query in Python, you need to set Python up so that it can interpret the specific SQL dialect and find the database that it is running the query on. The SQLAlchemy function `create_engine()` will give Python everything it needs to do this, but you also have to feed in the following parameters as a string (example given in code):

- SQL dialect ('mssql')
- Python library for interacting with the database ('pyodbc')
- Database location
- SQL driver ('?driver=SQL+Server')

```{python}
#| label: engine

engine = sa.create_engine('mssql+pyodbc://{server-and-db-address}?driver=SQL+Server',echo = True)

```

Having specified a SQL engine, you can establish a connection.

```{python}
#| label: connection

conn = engine.connect()

```

## Running SQL Query

You have two ways of going about running a SQL query in a Python script. You can either write your query out explicitly in your Python script, or you can read in an external SQL query. If the query is particularly lengthy, it is better to store is as a .sql file and call it from Python, to make it easier to read your code, and to maintain both components.

```{python}
#| label: query

# open and read sql query
query = open('path-to-query\query.sql', 'r')

# read query in to pandas dataframe
df = pd.read_sql_query(query.read(),conn)

# close sql query
query.close()

```

You can check that this process has worked as expected by inspecting your pandas dataframe.

```{python}
#| label: check

df.head()

```

## Export to CSV

Finally, you can export your dataframe using the pandas function `to_csv()`. If you want to retain the index column that pandas adds to the dataframe, simply change `index=False` to `True`.

```{python}
#| label: export

df.to_csv('path-to-save-df\df.csv', index=False)

```