{
  "hash": "346226fd779039a4f6fdc95ba73a8e81",
  "result": {
    "markdown": "---\nexecute:\n  eval: false\n---\n\n\n# Importing Data from SQL {#sec-sql}\n\n::: {.content-visible when-profile=\"python\"}\n\n\n::: {.cell hash='sql_cache/html/py-setup_a8b2de90666194985b4e0b94079c2f00'}\n\n```{.python .cell-code  code-fold=\"true\" code-summary=\"Setup Code (Click to Expand)\"}\nimport pyodbc\nimport sqlalchemy as sa\nimport pandas as pd\n\nfrom sqlalchemy import create_engine\n```\n:::\n\n\n:::\n\nOne of the first tasks you will need to do with any analysis is loading in the data. While you may have data from a variety of sources, the most common will be in a SQL database. Here we will cover how to access a SQL database and extract data in R.\n\n**NOTE: Unlike other notebooks, this notebook won't run and give you outputs because it does not contain the SQL server connection and database details that it needs to pull data. You need to fill in those blanks if you want to run the code below.**\n\n## Packages\n\n::: {.content-visible when-profile=\"r\"}\n\nThe R packages you need to interact with SQL are:\n\n-   DBI\n-   ODBC\n\n:::\n\n::: {.content-visible when-profile=\"python\"}\n\n\nThe python packages you need to interact with SQL are:\n\n- pyodbc - accessing ODBC databases\n- sqlalchemy - establishing a connection and interacts with pandas\n- pandas - storing, manipulating, and exporting dataframes\n\n:::\n\nI won't import either package here because they are only needed for a handful of functions.\n\n## Establish SQL Connection\n\n::: {.content-visible when-profile=\"r\"}\n\n\n::: {.cell hash='sql_cache/html/r-connection_3ca62d5cf9428f09471cedac84f949f3'}\n\n```{.r .cell-code}\ncon <- DBI::dbConnect(\n  odbc::odbc(),\n  driver = 'SQL Server',\n  server = '{db-server}',\n  database = '{db-name}',\n  trustedconnection = TRUE\n)\n```\n:::\n\n\n:::\n\n::: {.content-visible when-profile=\"python\"}\n\nIn order to run a SQL query in Python, you need to set Python up so that it can interpret the specific SQL dialect and find the database that it is running the query on. The SQLAlchemy function `create_engine()` will give Python everything it needs to do this, but you also have to feed in the following parameters as a string (example given in code):\n\n- SQL dialect ('mssql')\n- Python library for interacting with the database ('pyodbc')\n- Database location\n- SQL driver ('?driver=SQL+Server')\n\n\n::: {.cell hash='sql_cache/html/py-engine_29f724babfd8b31bea8c66aeb84ad7f5'}\n\n```{.python .cell-code}\nengine = sa.create_engine('mssql+pyodbc://{server-and-db-address}?driver=SQL+Server',echo = True)\n```\n:::\n\n\nHaving specified a SQL engine, you can establish a connection.\n\n\n::: {.cell hash='sql_cache/html/py-connection_51e2f89f808a84b81cf7518cdf783493'}\n\n```{.python .cell-code}\nconn = engine.connect()\n```\n:::\n\n\n:::\n\n## Running SQL Query\n\n::: {.content-visible when-profile=\"r\"}\n\n\n::: {.cell hash='sql_cache/html/r-query_7b40e657c9902ba064f92d1929fa8633'}\n\n```{.r .cell-code}\ndf <- DBI::dbGetQuery(\n  con,\n  'SELECT col_1,\n          col_2,\n          col_3\n  FROM    db_name.table_name'\n)\n```\n:::\n\n::: {.cell hash='sql_cache/html/r-check_5119cde2f44980134bdd3a1ec2b8f9ca'}\n\n```{.r .cell-code}\nhead(df)\n\ndplyr::glimpse(df)\n```\n:::\n\n\n:::\n\n::: {.content-visible when-profile=\"python\"}\n\nYou have two ways of going about running a SQL query in a Python script. You can either write your query out explicitly in your Python script, or you can read in an external SQL query. If the query is particularly lengthy, it is better to store is as a .sql file and call it from Python, to make it easier to read your code, and to maintain both components.\n\n\n::: {.cell hash='sql_cache/html/py-query_c77df59147e355bc1317befc879c48c2'}\n\n```{.python .cell-code}\n# open and read sql query\nquery = open('path-to-query\\query.sql', 'r')\n\n# read query in to pandas dataframe\ndf = pd.read_sql_query(query.read(),conn)\n\n# close sql query\nquery.close()\n```\n:::\n\n\nYou can check that this process has worked as expected by inspecting your pandas dataframe.\n\n\n::: {.cell hash='sql_cache/html/py-check_3ae3efdf554680388918dabad9e8789a'}\n\n```{.python .cell-code}\ndf.head()\n```\n:::\n\n\n:::\n\n## Export to CSV\n\n::: {.content-visible when-profile=\"r\"}\n\n\n::: {.cell hash='sql_cache/html/r-export_042a3220ecc5a9f60e0fad386c314f2c'}\n\n```{.r .cell-code}\nreadr::write_csv(df, here::here('path-to-save-df', 'df.csv'))\n```\n:::\n\n\n:::\n\n::: {.content-visible when-profile=\"python\"}\n\nFinally, you can export your dataframe using the pandas function `to_csv()`. If you want to retain the index column that pandas adds to the dataframe, simply change `index=False` to `True`.\n\n\n::: {.cell hash='sql_cache/html/py-export_491c97d11b648a2d6f59d586c5237d0d'}\n\n```{.python .cell-code}\ndf.to_csv('path-to-save-df\\df.csv', index=False)\n```\n:::\n\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}