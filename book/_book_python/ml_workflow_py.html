<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Python Data Science Guides - 8&nbsp; End-to-End Machine Learning Workflow</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./references.html" rel="next">
<link href="./linear_regression_py.html" rel="prev">
<link href="./figures/favicon.ico" rel="icon">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./ml_workflow_py.html">Machine Learning</a></li><li class="breadcrumb-item"><a href="./ml_workflow_py.html"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">End-to-End Machine Learning Workflow</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      <img src="./figures/scw_logo.jpg" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Python Data Science Guides</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/NHS-South-Central-and-West/data-science-guides/tree/main/book/" rel="" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./good_science.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Doing Good Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Dealing with Data</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./sql.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Importing Data from SQL</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./wrangling_py.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Wrangling Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eda_py.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Exploratory Data Analysis</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Statistical Inference</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hypothesis_testing_py.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Hypothesis Testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./linear_regression_py.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Linear Regression</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Machine Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ml_workflow_py.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">End-to-End Machine Learning Workflow</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Deep Learning</span></span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Delivering Data Science</span></span>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./version_control.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Version Control</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#data" id="toc-data" class="nav-link active" data-scroll-target="#data"><span class="header-section-number">8.1</span> Data</a>
  <ul class="collapse">
  <li><a href="#cleaning" id="toc-cleaning" class="nav-link" data-scroll-target="#cleaning"><span class="header-section-number">8.1.1</span> Cleaning</a></li>
  <li><a href="#traintest-split" id="toc-traintest-split" class="nav-link" data-scroll-target="#traintest-split"><span class="header-section-number">8.1.2</span> Train/Test Split</a></li>
  <li><a href="#preprocessing" id="toc-preprocessing" class="nav-link" data-scroll-target="#preprocessing"><span class="header-section-number">8.1.3</span> Preprocessing</a></li>
  </ul></li>
  <li><a href="#model-training" id="toc-model-training" class="nav-link" data-scroll-target="#model-training"><span class="header-section-number">8.2</span> Model Training</a>
  <ul class="collapse">
  <li><a href="#cross-validation" id="toc-cross-validation" class="nav-link" data-scroll-target="#cross-validation"><span class="header-section-number">8.2.1</span> Cross-Validation</a></li>
  <li><a href="#hyperparameter-tuning" id="toc-hyperparameter-tuning" class="nav-link" data-scroll-target="#hyperparameter-tuning"><span class="header-section-number">8.2.2</span> Hyperparameter Tuning</a></li>
  </ul></li>
  <li><a href="#model-evaluation" id="toc-model-evaluation" class="nav-link" data-scroll-target="#model-evaluation"><span class="header-section-number">8.3</span> Model Evaluation</a></li>
  <li><a href="#model-interpretation" id="toc-model-interpretation" class="nav-link" data-scroll-target="#model-interpretation"><span class="header-section-number">8.4</span> Model Interpretation</a></li>
  <li><a href="#next-steps" id="toc-next-steps" class="nav-link" data-scroll-target="#next-steps"><span class="header-section-number">8.5</span> Next Steps</a></li>
  <li><a href="#resources" id="toc-resources" class="nav-link" data-scroll-target="#resources"><span class="header-section-number">8.6</span> Resources</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/NHS-South-Central-and-West/data-science-guides/issues/new" class="toc-action">Report an issue</a></p><p><a href="https://github.com/NHS-South-Central-and-West/data-science-guides/blob/main/book/ml_workflow_py.qmd" class="toc-action">View source</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="sec-ml-workflow" class="quarto-section-identifier"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">End-to-End Machine Learning Workflow</span></span></h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<div id="setup" class="cell" data-execution_count="2">
<details>
<summary>Setup Code (Click to Expand)</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># import libraries</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> rc</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.compose <span class="im">import</span> ColumnTransformer</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> f1_score</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_val_score</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> StratifiedKFold</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> make_pipeline, Pipeline</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> OneHotEncoder, StandardScaler</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co"># import data</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"https://raw.githubusercontent.com/NHS-South-Central-and-West/data-science-guides/main/data/heart_disease.csv"</span>)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="co"># set plot style</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>sns.set_style(<span class="st">'whitegrid'</span>)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="co"># set plot font</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>rc(<span class="st">'font'</span>,<span class="op">**</span>{<span class="st">'family'</span>:<span class="st">'sans-serif'</span>,<span class="st">'sans-serif'</span>:[<span class="st">'Arial'</span>]})</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="co"># set plot colour palette</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>colours <span class="op">=</span> [<span class="st">'#1C355E'</span>, <span class="st">'#00A499'</span>, <span class="st">'#005EB8'</span>]</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>sns.set_palette(sns.color_palette(colours))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>An end-to-end machine learning workflow can be broken down into many steps, and there are an extensive number of layers of complexity that can be added, serving a variety of purposes. However, in this guide we will work through a bare bones workflow, using a simple dataset, in order to get a better understanding of the process.</p>
<p>A simple end-to-end ML solution will typically include the following steps:</p>
<ol type="1">
<li>Importing &amp; Cleaning Data</li>
<li>Exploratory Data Analysis (See <a href="eda_py.html"><span>Chapter&nbsp;5</span></a>)</li>
<li>Data Preprocessing</li>
<li>Model Training
<ul>
<li>Selecting from Candidate Models</li>
<li>Hyperparameter Tuning</li>
<li>Identifying Best Model</li>
</ul></li>
<li>Fitting Model on Test Data</li>
<li>Model Evaluation</li>
</ol>
<section id="data" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="data"><span class="header-section-number">8.1</span> Data</h2>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># data summary</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>df.info()</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>df.describe()</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 918 entries, 0 to 917
Data columns (total 10 columns):
 #   Column              Non-Null Count  Dtype  
---  ------              --------------  -----  
 0   age                 918 non-null    int64  
 1   sex                 918 non-null    object 
 2   resting_bp          918 non-null    int64  
 3   cholesterol         918 non-null    int64  
 4   fasting_bs          918 non-null    int64  
 5   resting_ecg         918 non-null    object 
 6   max_hr              918 non-null    int64  
 7   angina              918 non-null    object 
 8   heart_peak_reading  918 non-null    float64
 9   heart_disease       918 non-null    int64  
dtypes: float64(1), int64(6), object(3)
memory usage: 71.8+ KB</code></pre>
</div>
<div id="data_summary" class="cell-output cell-output-display" data-execution_count="2">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">age</th>
<th data-quarto-table-cell-role="th">sex</th>
<th data-quarto-table-cell-role="th">resting_bp</th>
<th data-quarto-table-cell-role="th">cholesterol</th>
<th data-quarto-table-cell-role="th">fasting_bs</th>
<th data-quarto-table-cell-role="th">resting_ecg</th>
<th data-quarto-table-cell-role="th">max_hr</th>
<th data-quarto-table-cell-role="th">angina</th>
<th data-quarto-table-cell-role="th">heart_peak_reading</th>
<th data-quarto-table-cell-role="th">heart_disease</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>40</td>
<td>M</td>
<td>140</td>
<td>289</td>
<td>0</td>
<td>Normal</td>
<td>172</td>
<td>N</td>
<td>0.0</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>49</td>
<td>F</td>
<td>160</td>
<td>180</td>
<td>0</td>
<td>Normal</td>
<td>156</td>
<td>N</td>
<td>1.0</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>37</td>
<td>M</td>
<td>130</td>
<td>283</td>
<td>0</td>
<td>ST</td>
<td>98</td>
<td>N</td>
<td>0.0</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>48</td>
<td>F</td>
<td>138</td>
<td>214</td>
<td>0</td>
<td>Normal</td>
<td>108</td>
<td>Y</td>
<td>1.5</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>54</td>
<td>M</td>
<td>150</td>
<td>195</td>
<td>0</td>
<td>Normal</td>
<td>122</td>
<td>N</td>
<td>0.0</td>
<td>0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<section id="cleaning" class="level3" data-number="8.1.1">
<h3 data-number="8.1.1" class="anchored" data-anchor-id="cleaning"><span class="header-section-number">8.1.1</span> Cleaning</h3>
<p>Though in this instance, the data is relatively clean, the following steps are included to demonstrate how you might clean data in a real-world scenario. Dropping NAs and duplicates should, however, be done with care (see discussion below).</p>
<div id="data_cleaning" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># check for missing values</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>df.isna().<span class="bu">sum</span>()</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># drop missing values</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>df.dropna(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co"># check for duplicates</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>df.duplicated().<span class="bu">sum</span>()</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co"># drop duplicates</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>df.drop_duplicates(inplace<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>There are several variables for which there appear to be missing values in the form of zeroes. This was identified in the exploratory data analysis notebook in this project. Variables like <code>cholesterol</code> and <code>resting_bp</code> should not be zero, and because the target class is disproportionately distributed within these zero values, it is important to address the problem.</p>
<p>There are a number of choices that could be made when it comes to dealing with null or missing values, and there are robust approaches to imputation (though it is necessary to take great care when doing so), however in the interest of simplicity, we will simply remove the rows with zero values in this instance.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<div id="remove-zero-values" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># remove zero values</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df[(df[<span class="st">'cholesterol'</span>] <span class="op">!=</span> <span class="dv">0</span>) <span class="op">&amp;</span> (df[<span class="st">'resting_bp'</span>] <span class="op">!=</span> <span class="dv">0</span>)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="traintest-split" class="level3" data-number="8.1.2">
<h3 data-number="8.1.2" class="anchored" data-anchor-id="traintest-split"><span class="header-section-number">8.1.2</span> Train/Test Split</h3>
<p>One of the central tenets of machine learning is that the model should not be trained on the same data that it is evaluated on. This is because the model could learn spurious/random patterns and correlations in the training data, and this will harm the model’s ability to make good predictions on new, unseen data. There are many way of trying to resolve this, but the most simple approach is to split the data into a training and test set. The training set will be used to train the model, and the test set will be used to evaluate the model.</p>
<div id="train_test_split" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># split data into train and test sets</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.drop(<span class="st">'heart_disease'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">'heart_disease'</span>]</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="preprocessing" class="level3" data-number="8.1.3">
<h3 data-number="8.1.3" class="anchored" data-anchor-id="preprocessing"><span class="header-section-number">8.1.3</span> Preprocessing</h3>
<p>The purpose of preprocessing is to prepare the data for model fitting. This can take a number of different forms, but some of the most common preprocessing steps include:</p>
<ul>
<li>Normalising/Standardising data</li>
<li>One-hot encoding categorical variables</li>
<li>Removing outliers</li>
<li>Imputing missing values</li>
</ul>
<p>We will build a preprocessing recipe that one-hot encodes all categorical features, and normalises the numeric features so that they have a mean of zero and a standard deviation of one.</p>
<div id="preprocessing" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># specify all features for the model</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>feats <span class="op">=</span> df.drop(<span class="st">'heart_disease'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># specify target</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>target <span class="op">=</span> [<span class="st">'heart_disease'</span>]</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="co"># get categorical columns</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>cat_cols <span class="op">=</span> df.select_dtypes(include<span class="op">=</span><span class="st">'object'</span>).columns</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="co"># get numerical columns (excluding target)</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>num_cols <span class="op">=</span> df.drop(<span class="st">'heart_disease'</span>, axis<span class="op">=</span><span class="dv">1</span>).select_dtypes(exclude<span class="op">=</span><span class="st">'object'</span>).columns</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> Pipeline(steps<span class="op">=</span>[(<span class="st">'scaler'</span>, StandardScaler())])</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>one_hot <span class="op">=</span> Pipeline(steps<span class="op">=</span>[(<span class="st">'one_hot'</span>, OneHotEncoder(drop<span class="op">=</span><span class="st">'first'</span>))])</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>preprocess <span class="op">=</span> ColumnTransformer(</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    transformers<span class="op">=</span>[</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>        (<span class="st">'nums'</span>, scaler, num_cols),</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>        (<span class="st">'cats'</span>, one_hot, cat_cols)</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>        ])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="model-training" class="level2" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="model-training"><span class="header-section-number">8.2</span> Model Training</h2>
<p>There are many different types of models that can be used for classification problems, and selecting the right model for the problem at hand can be difficult when you are first starting out with machine learning.</p>
<p>Simple models like <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html">linear</a> and <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html">logistic</a> regressions are often a good place to start and can be used to get a better understanding of the data and the problem at hand, and can give you a good idea of baseline performance before building more complex models to improve performance. Another example of a simple model is <a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html">K-Nearest Neighbours</a> (KNN), which is a non-parametric model that can be used for both classification and regression problems.</p>
<p>We will fit a logistic regression and a KNN, as well as fitting a Random Forest model, which is a good example of a slightly more complex model that will often perform well on structured data.</p>
<section id="cross-validation" class="level3" data-number="8.2.1">
<h3 data-number="8.2.1" class="anchored" data-anchor-id="cross-validation"><span class="header-section-number">8.2.1</span> Cross-Validation</h3>
<p>On top of the train/test split, we will also use cross-validation to train our models. Cross-validation is a method of training a model on a subset of the data, and then evaluating the model on the remaining data. This process is repeated multiple times, and the average performance is used to evaluate the model. This helps make the training process more generalisable.</p>
<p>For more information on cross-validation and how it can be used to train models:</p>
<ul>
<li>The <a href="https://scikit-learn.org/stable/modules/cross_validation.html">Cross-Validation</a> section in the Scikit-learn documentation provides a good overview of cross-validation and how it can be used to train models. It includes a discussion of a typical cross-validation workflow; the different types of cross-validation, their implementation in Scikit-learn, and their pros and cons; and the documentation is accompanied by a lot of really helpful visuals.</li>
<li>Neptune AI’s <a href="https://neptune.ai/blog/cross-validation-in-machine-learning-how-to-do-it-right">blog post</a> on cross-validation goes into detail discussing cross-validation strategies, and gives clear visual demonstrations of how each strategy works.</li>
</ul>
<p>We will use 5-fold stratified cross-validation to train our models. This means that the training data will be split into 5 folds, ensuring that each fold has the same proportion of the target classes. Each fold will be used as a test set once, and the remaining folds will be used as training sets. This will be repeated 5 times, and the average performance will be used to evaluate the model.</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># select </span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> []</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>models.append((<span class="st">'log'</span>, LogisticRegression(random_state<span class="op">=</span><span class="dv">123</span>)))</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>models.append((<span class="st">'knn'</span>, KNeighborsClassifier()))</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>models.append((<span class="st">'rf'</span>, RandomForestClassifier(random_state<span class="op">=</span><span class="dv">123</span>)))</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co"># evaluate each model in turn</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> []</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>names <span class="op">=</span> []</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>n_splits <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, model <span class="kw">in</span> models:</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>  kf <span class="op">=</span> StratifiedKFold(n_splits, random_state<span class="op">=</span><span class="dv">123</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>  pipeline <span class="op">=</span> Pipeline([</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'preprocess'</span>, preprocess),</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'model'</span>, model)</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>  cv_scores <span class="op">=</span> cross_val_score(</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>    pipeline, </span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>    X_train, </span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>    y_train, </span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>    cv<span class="op">=</span>kf, </span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>    scoring<span class="op">=</span><span class="st">'f1'</span></span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>  results.append(cv_scores)</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>  names.append(name)</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="st">'</span><span class="sc">%s</span><span class="st">: </span><span class="sc">%.2f</span><span class="st"> (</span><span class="sc">%.3f</span><span class="st">)'</span> <span class="op">%</span> (name, cv_scores.mean(), cv_scores.std()))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>log: 0.79 (0.025)
knn: 0.74 (0.018)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>rf: 0.77 (0.032)</code></pre>
</div>
</div>
<p>Although the logistic regression performs slightly better than the random forest, the random forest has higher standard deviation and has more hyperparameters that can be tuned, so it is likely this will model has the highest potential.</p>
</section>
<section id="hyperparameter-tuning" class="level3" data-number="8.2.2">
<h3 data-number="8.2.2" class="anchored" data-anchor-id="hyperparameter-tuning"><span class="header-section-number">8.2.2</span> Hyperparameter Tuning</h3>
<p>Having defined the preprocessing pipeline, we can now train and tune the models. We will use the <code>GridSearchCV()</code> function to carry out hyperparameter tuning[^tuning], which will search over a grid of hyperparameter values (specified by <code>params</code>) to find the best performing model. We will use 5-fold cross-validation to train the models, and will evaluate the models using F1 score and accuracy.</p>
<p>For a more detailed discussion of hyperparameter tuning, and the different methods for tuning in Scikit-learn, the <a href="https://scikit-learn.org/stable/modules/grid_search.html#">Tuning the Hyperparameters of an Estimator</a> section of the Scikit-learn documentation is a good place to start, and the <a href="https://inria.github.io/scikit-learn-mooc/python_scripts/parameter_tuning_grid_search.html">Hyperparameter Tuning by Grid Search</a> section of the Scikit-learn course is an excellent accompaniment.</p>
<p>In addition, the AWS overview of <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html">hyperparameter tuning</a> is a good resource if you are only looking for a brief overview. For an in-depth discussion about how hyperparameter tuning works, including the mathematics behind it, Jeremy Jordan’s <a href="https://www.jeremyjordan.me/hyperparameter-tuning/">Hyperparameter Tuning for Machine Learning Models</a> blogpost is thorough but easy to follow.</p>
<p>There are a lot of different Python libraries for hyperparameter tuning, however the most popular libraries that are specifically designed for tuning are <a href="http://hyperopt.github.io/hyperopt/">Hyperopt</a> and <a href="https://optuna.org/">Optuna</a>. Both can be used to tune models built with Scikit-learn (and many other frameworks) and can often produce better results than Scikit-learn’s built-in hyperparameter tuning methods. I have had limited experience using Hyperopt, however I have used Optuna often and I would highly recommend it if/when you are ready to move beyond Scikit-learn’s options for tuning.</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> { </span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>  <span class="st">'rf__bootstrap'</span>: [<span class="va">True</span>],</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>  <span class="st">'rf__max_depth'</span>: [<span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">30</span>],</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>  <span class="st">"rf__min_samples_leaf"</span> : [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>],</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>  <span class="st">"rf__min_samples_split"</span> : [<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">10</span>],</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>  <span class="st">"rf__n_estimators"</span>: [<span class="dv">100</span>, <span class="dv">250</span>, <span class="dv">500</span>]</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>pipeline <span class="op">=</span> Pipeline([</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'preprocess'</span>, preprocess),</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'rf'</span>, RandomForestClassifier(random_state<span class="op">=</span><span class="dv">123</span>))</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> GridSearchCV(</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>  estimator<span class="op">=</span>pipeline,</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>  param_grid<span class="op">=</span>params,</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>  scoring<span class="op">=</span><span class="st">'f1'</span>,</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>  cv<span class="op">=</span>kf,</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>  verbose<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>  refit<span class="op">=</span><span class="va">True</span></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a><span class="co"># tune random forest</span></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>tuning_results <span class="op">=</span> clf.fit(X_train, y_train)</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a><span class="co"># get the f1 score for training set</span></span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Training F1 Score: </span><span class="sc">%.2f</span><span class="st">'</span> <span class="op">%</span> (tuning_results.best_score_))</span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a><span class="co"># get the best performing model on training set</span></span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>best_model <span class="op">=</span> tuning_results.best_estimator_</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Fitting 5 folds for each of 81 candidates, totalling 405 fits</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Training F1 Score: 0.79</code></pre>
</div>
</div>
</section>
</section>
<section id="model-evaluation" class="level2" data-number="8.3">
<h2 data-number="8.3" class="anchored" data-anchor-id="model-evaluation"><span class="header-section-number">8.3</span> Model Evaluation</h2>
<div id="evaluation" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get predictions on holdout set</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> best_model.predict(X_test)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># get the f1 score for holdout sets</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Holdout F1 Score: </span><span class="sc">%.2f</span><span class="st">'</span> <span class="op">%</span> (f1_score(y_test, preds)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Holdout F1 Score: 0.82</code></pre>
</div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get confusion matrix</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>conf_mat <span class="op">=</span> pd.crosstab(y_test, preds, rownames<span class="op">=</span>[<span class="st">'Actual'</span>], colnames<span class="op">=</span>[<span class="st">'Predicted'</span>])</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co"># plot confusion matrix</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>sns.heatmap(</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> conf_mat,</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    annot<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    cmap<span class="op">=</span><span class="st">'Blues'</span>,</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    fmt<span class="op">=</span><span class="st">'g'</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>sns.despine()</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="ml_workflow_py_files/figure-html/confusion-matrix-output-1.png" id="confusion-matrix" width="737" height="501"></p>
</div>
</div>
</section>
<section id="model-interpretation" class="level2" data-number="8.4">
<h2 data-number="8.4" class="anchored" data-anchor-id="model-interpretation"><span class="header-section-number">8.4</span> Model Interpretation</h2>
<p>We can compute the features that are most important in predicting heart disease.</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get feature importance</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>feature_importance <span class="op">=</span> best_model.named_steps[<span class="st">'rf'</span>].feature_importances_</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># get feature names</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>feature_names <span class="op">=</span> (</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    best_model</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    .named_steps[<span class="st">'preprocess'</span>]</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    .transformers_[<span class="dv">1</span>][<span class="dv">1</span>]</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>    .named_steps[<span class="st">'one_hot'</span>]</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>    .get_feature_names_out(cat_cols)</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>    .tolist()</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="co"># get feature names</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>feature_names <span class="op">=</span> num_cols.tolist() <span class="op">+</span> feature_names</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a><span class="co"># create dataframe</span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>feat_importance <span class="op">=</span> pd.DataFrame({</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>  <span class="st">'feature'</span>: feature_names, </span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>  <span class="st">'importance'</span>: feature_importance</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a><span class="co"># plot feature importance</span></span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>sns.barplot(</span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>    x<span class="op">=</span><span class="st">'importance'</span>,</span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a>    y<span class="op">=</span><span class="st">'feature'</span>,</span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>    data<span class="op">=</span>feat_importance.sort_values(by<span class="op">=</span><span class="st">'importance'</span>, ascending<span class="op">=</span><span class="va">False</span>),</span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a>    color<span class="op">=</span><span class="st">'#1C355E'</span></span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>sns.despine()</span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="ml_workflow_py_files/figure-html/feature-importance-output-1.png" id="feature-importance" width="909" height="501"></p>
</div>
</div>
</section>
<section id="next-steps" class="level2" data-number="8.5">
<h2 data-number="8.5" class="anchored" data-anchor-id="next-steps"><span class="header-section-number">8.5</span> Next Steps</h2>
</section>
<section id="resources" class="level2" data-number="8.6">
<h2 data-number="8.6" class="anchored" data-anchor-id="resources"><span class="header-section-number">8.6</span> Resources</h2>
<p>There are lots of great (and free) introductory resources for machine learning:</p>
<ul>
<li><a href="https://aws.amazon.com/machine-learning/mlu">Machine Learning University</a></li>
<li><a href="https://mlu-explain.github.io/">MLU Explain</a></li>
<li><a href="https://microsoft.github.io/ML-For-Beginners/?utm_source=substack&amp;utm_medium=email#/">Machine Learning for Beginners</a></li>
</ul>
<p>For a guided video course, Data Talks Club’s Machine Learning Zoomcamp (available on <a href="https://github.com/alexeygrigorev/mlbookcamp-code/tree/master/course-zoomcamp">Github</a> and <a href="https://www.youtube.com/watch?v=MqI8vt3-cag&amp;list=PL3MmuxUbc_hIhxl5Ji8t4O6lPAOpHaCLR">Youtube</a>) is well-paced and well-presented, covering a variety of machine learning methods and even covering some of the aspects that introductory course often skip over, like deployment and data engineering principles. However, while the ML Zoomcamp course is intended as an introduction to machine learning, it does assume a certain level of familiarity with programming (the course uses Python) and software engineering. The appendix section of the course is definitely helpful for bridging some of the gaps in the course, but it is still worth being aware of the way the course is structured.</p>
<p>If you are looking for something that goes into greater detail about a wide range of machine learning methods, then there is no better resource than <a href="https://hastie.su.domains/ISLR2/ISLRv2_website.pdf">An Introduction to Statistical Learning</a> (or its accompanying <a href="https://www.statlearning.com/online-course">online course</a>), by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani.</p>
<p>Finally, if you are particularly interested in learning the mathematics that underpins machine learning, I would highly recommend <a href="https://tivadardanka.com/books/mathematics-of-machine-learning">Mathematics of Machine Learning</a>, which is admittedly not free but is very, very good. If you want to learn about the mathematics of machine learning but are not comfortable enough tackling the Mathematics of ML book, the <a href="https://www.youtube.com/channel/UCtYLUTtgS3k1Fg4y5tAhLbw">StatQuest</a> and <a href="https://www.youtube.com/c/3blue1brown">3Blue1Brown</a> Youtube channels are both really accessible and well-presented.</p>


<!-- -->

</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>In a real-world analysis, it would be important to understand why the data is missing, and to consider the implications of removing the data. For example, if the data is missing at random, then removing the data will not have a significant impact on the analysis. However, if the data is missing because it was not collected, or if the data is missing because it is not available, then removing the data could have a significant impact on the analysis.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./linear_regression_py.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Linear Regression</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./references.html" class="pagination-link">
        <span class="nav-page-text">References</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb18" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># End-to-End Machine Learning Workflow {#sec-ml-workflow}</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: setup</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: 'Setup Code (Click to Expand)'</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="co"># import libraries</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> rc</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.compose <span class="im">import</span> ColumnTransformer</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> f1_score</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_val_score</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> StratifiedKFold</span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> make_pipeline, Pipeline</span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> OneHotEncoder, StandardScaler</span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a><span class="co"># import data</span></span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"https://raw.githubusercontent.com/NHS-South-Central-and-West/data-science-guides/main/data/heart_disease.csv"</span>)</span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a><span class="co"># set plot style</span></span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>sns.set_style(<span class="st">'whitegrid'</span>)</span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a><span class="co"># set plot font</span></span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a>rc(<span class="st">'font'</span>,<span class="op">**</span>{<span class="st">'family'</span>:<span class="st">'sans-serif'</span>,<span class="st">'sans-serif'</span>:[<span class="st">'Arial'</span>]})</span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a><span class="co"># set plot colour palette</span></span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a>colours <span class="op">=</span> [<span class="st">'#1C355E'</span>, <span class="st">'#00A499'</span>, <span class="st">'#005EB8'</span>]</span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a>sns.set_palette(sns.color_palette(colours))</span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a>An end-to-end machine learning workflow can be broken down into many steps, and there are an extensive number of layers of complexity that can be added, serving a variety of purposes. However, in this guide we will work through a bare bones workflow, using a simple dataset, in order to get a better understanding of the process.</span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a>A simple end-to-end ML solution will typically include the following steps:</span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Importing &amp; Cleaning Data</span>
<span id="cb18-50"><a href="#cb18-50" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Exploratory Data Analysis (See @sec-eda)</span>
<span id="cb18-51"><a href="#cb18-51" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Data Preprocessing</span>
<span id="cb18-52"><a href="#cb18-52" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Model Training</span>
<span id="cb18-53"><a href="#cb18-53" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>Selecting from Candidate Models</span>
<span id="cb18-54"><a href="#cb18-54" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>Hyperparameter Tuning</span>
<span id="cb18-55"><a href="#cb18-55" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>Identifying Best Model</span>
<span id="cb18-56"><a href="#cb18-56" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>Fitting Model on Test Data</span>
<span id="cb18-57"><a href="#cb18-57" aria-hidden="true" tabindex="-1"></a><span class="ss">6. </span>Model Evaluation</span>
<span id="cb18-58"><a href="#cb18-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-59"><a href="#cb18-59" aria-hidden="true" tabindex="-1"></a><span class="fu">## Data</span></span>
<span id="cb18-60"><a href="#cb18-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-63"><a href="#cb18-63" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-64"><a href="#cb18-64" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: data_summary</span></span>
<span id="cb18-65"><a href="#cb18-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-66"><a href="#cb18-66" aria-hidden="true" tabindex="-1"></a><span class="co"># data summary</span></span>
<span id="cb18-67"><a href="#cb18-67" aria-hidden="true" tabindex="-1"></a>df.info()</span>
<span id="cb18-68"><a href="#cb18-68" aria-hidden="true" tabindex="-1"></a>df.describe()</span>
<span id="cb18-69"><a href="#cb18-69" aria-hidden="true" tabindex="-1"></a>df.head()</span>
<span id="cb18-70"><a href="#cb18-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-71"><a href="#cb18-71" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-72"><a href="#cb18-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-73"><a href="#cb18-73" aria-hidden="true" tabindex="-1"></a><span class="fu">### Cleaning</span></span>
<span id="cb18-74"><a href="#cb18-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-75"><a href="#cb18-75" aria-hidden="true" tabindex="-1"></a>Though in this instance, the data is relatively clean, the following steps are included to demonstrate how you might clean data in a real-world scenario. Dropping NAs and duplicates should, however, be done with care (see discussion below).</span>
<span id="cb18-76"><a href="#cb18-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-79"><a href="#cb18-79" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-80"><a href="#cb18-80" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: data_cleaning</span></span>
<span id="cb18-81"><a href="#cb18-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-82"><a href="#cb18-82" aria-hidden="true" tabindex="-1"></a><span class="co"># check for missing values</span></span>
<span id="cb18-83"><a href="#cb18-83" aria-hidden="true" tabindex="-1"></a>df.isna().<span class="bu">sum</span>()</span>
<span id="cb18-84"><a href="#cb18-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-85"><a href="#cb18-85" aria-hidden="true" tabindex="-1"></a><span class="co"># drop missing values</span></span>
<span id="cb18-86"><a href="#cb18-86" aria-hidden="true" tabindex="-1"></a>df.dropna(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-87"><a href="#cb18-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-88"><a href="#cb18-88" aria-hidden="true" tabindex="-1"></a><span class="co"># check for duplicates</span></span>
<span id="cb18-89"><a href="#cb18-89" aria-hidden="true" tabindex="-1"></a>df.duplicated().<span class="bu">sum</span>()</span>
<span id="cb18-90"><a href="#cb18-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-91"><a href="#cb18-91" aria-hidden="true" tabindex="-1"></a><span class="co"># drop duplicates</span></span>
<span id="cb18-92"><a href="#cb18-92" aria-hidden="true" tabindex="-1"></a>df.drop_duplicates(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-93"><a href="#cb18-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-94"><a href="#cb18-94" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-95"><a href="#cb18-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-96"><a href="#cb18-96" aria-hidden="true" tabindex="-1"></a>There are several variables for which there appear to be missing values in the form of zeroes. This was identified in the exploratory data analysis notebook in this project. Variables like <span class="in">`cholesterol`</span> and <span class="in">`resting_bp`</span> should not be zero, and because the target class is disproportionately distributed within these zero values, it is important to address the problem.</span>
<span id="cb18-97"><a href="#cb18-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-98"><a href="#cb18-98" aria-hidden="true" tabindex="-1"></a>There are a number of choices that could be made when it comes to dealing with null or missing values, and there are robust approaches to imputation (though it is necessary to take great care when doing so), however in the interest of simplicity, we will simply remove the rows with zero values in this instance.<span class="ot">[^1]</span></span>
<span id="cb18-99"><a href="#cb18-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-100"><a href="#cb18-100" aria-hidden="true" tabindex="-1"></a><span class="ot">[^1]: </span>In a real-world analysis, it would be important to understand why the data is missing, and to consider the implications of removing the data. For example, if the data is missing at random, then removing the data will not have a significant impact on the analysis. However, if the data is missing because it was not collected, or if the data is missing because it is not available, then removing the data could have a significant impact on the analysis.</span>
<span id="cb18-101"><a href="#cb18-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-104"><a href="#cb18-104" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-105"><a href="#cb18-105" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: remove-zero-values</span></span>
<span id="cb18-106"><a href="#cb18-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-107"><a href="#cb18-107" aria-hidden="true" tabindex="-1"></a><span class="co"># remove zero values</span></span>
<span id="cb18-108"><a href="#cb18-108" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df[(df[<span class="st">'cholesterol'</span>] <span class="op">!=</span> <span class="dv">0</span>) <span class="op">&amp;</span> (df[<span class="st">'resting_bp'</span>] <span class="op">!=</span> <span class="dv">0</span>)]</span>
<span id="cb18-109"><a href="#cb18-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-110"><a href="#cb18-110" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-111"><a href="#cb18-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-112"><a href="#cb18-112" aria-hidden="true" tabindex="-1"></a><span class="fu">### Train/Test Split</span></span>
<span id="cb18-113"><a href="#cb18-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-114"><a href="#cb18-114" aria-hidden="true" tabindex="-1"></a>One of the central tenets of machine learning is that the model should not be trained on the same data that it is evaluated on. This is because the model could learn spurious/random patterns and correlations in the training data, and this will harm the model's ability to make good predictions on new, unseen data. There are many way of trying to resolve this, but the most simple approach is to split the data into a training and test set. The training set will be used to train the model, and the test set will be used to evaluate the model.</span>
<span id="cb18-115"><a href="#cb18-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-118"><a href="#cb18-118" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-119"><a href="#cb18-119" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: train_test_split</span></span>
<span id="cb18-120"><a href="#cb18-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-121"><a href="#cb18-121" aria-hidden="true" tabindex="-1"></a><span class="co"># split data into train and test sets</span></span>
<span id="cb18-122"><a href="#cb18-122" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.drop(<span class="st">'heart_disease'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb18-123"><a href="#cb18-123" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">'heart_disease'</span>]</span>
<span id="cb18-124"><a href="#cb18-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-125"><a href="#cb18-125" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb18-126"><a href="#cb18-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-127"><a href="#cb18-127" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-128"><a href="#cb18-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-129"><a href="#cb18-129" aria-hidden="true" tabindex="-1"></a><span class="fu">### Preprocessing</span></span>
<span id="cb18-130"><a href="#cb18-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-131"><a href="#cb18-131" aria-hidden="true" tabindex="-1"></a>The purpose of preprocessing is to prepare the data for model fitting. This can take a number of different forms, but some of the most common preprocessing steps include:</span>
<span id="cb18-132"><a href="#cb18-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-133"><a href="#cb18-133" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Normalising/Standardising data</span>
<span id="cb18-134"><a href="#cb18-134" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>One-hot encoding categorical variables</span>
<span id="cb18-135"><a href="#cb18-135" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Removing outliers</span>
<span id="cb18-136"><a href="#cb18-136" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Imputing missing values</span>
<span id="cb18-137"><a href="#cb18-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-138"><a href="#cb18-138" aria-hidden="true" tabindex="-1"></a>We will build a preprocessing recipe that one-hot encodes all categorical features, and normalises the numeric features so that they have a mean of zero and a standard deviation of one.</span>
<span id="cb18-139"><a href="#cb18-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-142"><a href="#cb18-142" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-143"><a href="#cb18-143" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: preprocessing</span></span>
<span id="cb18-144"><a href="#cb18-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-145"><a href="#cb18-145" aria-hidden="true" tabindex="-1"></a><span class="co"># specify all features for the model</span></span>
<span id="cb18-146"><a href="#cb18-146" aria-hidden="true" tabindex="-1"></a>feats <span class="op">=</span> df.drop(<span class="st">'heart_disease'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb18-147"><a href="#cb18-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-148"><a href="#cb18-148" aria-hidden="true" tabindex="-1"></a><span class="co"># specify target</span></span>
<span id="cb18-149"><a href="#cb18-149" aria-hidden="true" tabindex="-1"></a>target <span class="op">=</span> [<span class="st">'heart_disease'</span>]</span>
<span id="cb18-150"><a href="#cb18-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-151"><a href="#cb18-151" aria-hidden="true" tabindex="-1"></a><span class="co"># get categorical columns</span></span>
<span id="cb18-152"><a href="#cb18-152" aria-hidden="true" tabindex="-1"></a>cat_cols <span class="op">=</span> df.select_dtypes(include<span class="op">=</span><span class="st">'object'</span>).columns</span>
<span id="cb18-153"><a href="#cb18-153" aria-hidden="true" tabindex="-1"></a><span class="co"># get numerical columns (excluding target)</span></span>
<span id="cb18-154"><a href="#cb18-154" aria-hidden="true" tabindex="-1"></a>num_cols <span class="op">=</span> df.drop(<span class="st">'heart_disease'</span>, axis<span class="op">=</span><span class="dv">1</span>).select_dtypes(exclude<span class="op">=</span><span class="st">'object'</span>).columns</span>
<span id="cb18-155"><a href="#cb18-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-156"><a href="#cb18-156" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> Pipeline(steps<span class="op">=</span>[(<span class="st">'scaler'</span>, StandardScaler())])</span>
<span id="cb18-157"><a href="#cb18-157" aria-hidden="true" tabindex="-1"></a>one_hot <span class="op">=</span> Pipeline(steps<span class="op">=</span>[(<span class="st">'one_hot'</span>, OneHotEncoder(drop<span class="op">=</span><span class="st">'first'</span>))])</span>
<span id="cb18-158"><a href="#cb18-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-159"><a href="#cb18-159" aria-hidden="true" tabindex="-1"></a>preprocess <span class="op">=</span> ColumnTransformer(</span>
<span id="cb18-160"><a href="#cb18-160" aria-hidden="true" tabindex="-1"></a>    transformers<span class="op">=</span>[</span>
<span id="cb18-161"><a href="#cb18-161" aria-hidden="true" tabindex="-1"></a>        (<span class="st">'nums'</span>, scaler, num_cols),</span>
<span id="cb18-162"><a href="#cb18-162" aria-hidden="true" tabindex="-1"></a>        (<span class="st">'cats'</span>, one_hot, cat_cols)</span>
<span id="cb18-163"><a href="#cb18-163" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb18-164"><a href="#cb18-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-165"><a href="#cb18-165" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-166"><a href="#cb18-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-167"><a href="#cb18-167" aria-hidden="true" tabindex="-1"></a><span class="fu">## Model Training</span></span>
<span id="cb18-168"><a href="#cb18-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-169"><a href="#cb18-169" aria-hidden="true" tabindex="-1"></a>There are many different types of models that can be used for classification problems, and selecting the right model for the problem at hand can be difficult when you are first starting out with machine learning.</span>
<span id="cb18-170"><a href="#cb18-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-171"><a href="#cb18-171" aria-hidden="true" tabindex="-1"></a>Simple models like <span class="co">[</span><span class="ot">linear</span><span class="co">](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)</span> and <span class="co">[</span><span class="ot">logistic</span><span class="co">](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)</span> regressions are often a good place to start and can be used to get a better understanding of the data and the problem at hand, and can give you a good idea of baseline performance before building more complex models to improve performance. Another example of a simple model is <span class="co">[</span><span class="ot">K-Nearest Neighbours</span><span class="co">](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)</span> (KNN), which is a non-parametric model that can be used for both classification and regression problems.</span>
<span id="cb18-172"><a href="#cb18-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-173"><a href="#cb18-173" aria-hidden="true" tabindex="-1"></a>We will fit a logistic regression and a KNN, as well as fitting a Random Forest model, which is a good example of a slightly more complex model that will often perform well on structured data.</span>
<span id="cb18-174"><a href="#cb18-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-175"><a href="#cb18-175" aria-hidden="true" tabindex="-1"></a><span class="fu">### Cross-Validation</span></span>
<span id="cb18-176"><a href="#cb18-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-177"><a href="#cb18-177" aria-hidden="true" tabindex="-1"></a>On top of the train/test split, we will also use cross-validation to train our models. Cross-validation is a method of training a model on a subset of the data, and then evaluating the model on the remaining data. This process is repeated multiple times, and the average performance is used to evaluate the model. This helps make the training process more generalisable.</span>
<span id="cb18-178"><a href="#cb18-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-179"><a href="#cb18-179" aria-hidden="true" tabindex="-1"></a>For more information on cross-validation and how it can be used to train models:</span>
<span id="cb18-180"><a href="#cb18-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-181"><a href="#cb18-181" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The <span class="co">[</span><span class="ot">Cross-Validation</span><span class="co">](https://scikit-learn.org/stable/modules/cross_validation.html)</span> section in the Scikit-learn documentation provides a good overview of cross-validation and how it can be used to train models. It includes a discussion of a typical cross-validation workflow; the different types of cross-validation, their implementation in Scikit-learn, and their pros and cons; and the documentation is accompanied by a lot of really helpful visuals.</span>
<span id="cb18-182"><a href="#cb18-182" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Neptune AI's <span class="co">[</span><span class="ot">blog post</span><span class="co">](https://neptune.ai/blog/cross-validation-in-machine-learning-how-to-do-it-right)</span> on cross-validation goes into detail discussing cross-validation strategies, and gives clear visual demonstrations of how each strategy works.</span>
<span id="cb18-183"><a href="#cb18-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-184"><a href="#cb18-184" aria-hidden="true" tabindex="-1"></a>We will use 5-fold stratified cross-validation to train our models. This means that the training data will be split into 5 folds, ensuring that each fold has the same proportion of the target classes. Each fold will be used as a test set once, and the remaining folds will be used as training sets. This will be repeated 5 times, and the average performance will be used to evaluate the model.</span>
<span id="cb18-185"><a href="#cb18-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-188"><a href="#cb18-188" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-189"><a href="#cb18-189" aria-hidden="true" tabindex="-1"></a><span class="co"># select </span></span>
<span id="cb18-190"><a href="#cb18-190" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> []</span>
<span id="cb18-191"><a href="#cb18-191" aria-hidden="true" tabindex="-1"></a>models.append((<span class="st">'log'</span>, LogisticRegression(random_state<span class="op">=</span><span class="dv">123</span>)))</span>
<span id="cb18-192"><a href="#cb18-192" aria-hidden="true" tabindex="-1"></a>models.append((<span class="st">'knn'</span>, KNeighborsClassifier()))</span>
<span id="cb18-193"><a href="#cb18-193" aria-hidden="true" tabindex="-1"></a>models.append((<span class="st">'rf'</span>, RandomForestClassifier(random_state<span class="op">=</span><span class="dv">123</span>)))</span>
<span id="cb18-194"><a href="#cb18-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-195"><a href="#cb18-195" aria-hidden="true" tabindex="-1"></a><span class="co"># evaluate each model in turn</span></span>
<span id="cb18-196"><a href="#cb18-196" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> []</span>
<span id="cb18-197"><a href="#cb18-197" aria-hidden="true" tabindex="-1"></a>names <span class="op">=</span> []</span>
<span id="cb18-198"><a href="#cb18-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-199"><a href="#cb18-199" aria-hidden="true" tabindex="-1"></a>n_splits <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb18-200"><a href="#cb18-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-201"><a href="#cb18-201" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, model <span class="kw">in</span> models:</span>
<span id="cb18-202"><a href="#cb18-202" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb18-203"><a href="#cb18-203" aria-hidden="true" tabindex="-1"></a>  kf <span class="op">=</span> StratifiedKFold(n_splits, random_state<span class="op">=</span><span class="dv">123</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-204"><a href="#cb18-204" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb18-205"><a href="#cb18-205" aria-hidden="true" tabindex="-1"></a>  pipeline <span class="op">=</span> Pipeline([</span>
<span id="cb18-206"><a href="#cb18-206" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'preprocess'</span>, preprocess),</span>
<span id="cb18-207"><a href="#cb18-207" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'model'</span>, model)</span>
<span id="cb18-208"><a href="#cb18-208" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb18-209"><a href="#cb18-209" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-210"><a href="#cb18-210" aria-hidden="true" tabindex="-1"></a>  cv_scores <span class="op">=</span> cross_val_score(</span>
<span id="cb18-211"><a href="#cb18-211" aria-hidden="true" tabindex="-1"></a>    pipeline, </span>
<span id="cb18-212"><a href="#cb18-212" aria-hidden="true" tabindex="-1"></a>    X_train, </span>
<span id="cb18-213"><a href="#cb18-213" aria-hidden="true" tabindex="-1"></a>    y_train, </span>
<span id="cb18-214"><a href="#cb18-214" aria-hidden="true" tabindex="-1"></a>    cv<span class="op">=</span>kf, </span>
<span id="cb18-215"><a href="#cb18-215" aria-hidden="true" tabindex="-1"></a>    scoring<span class="op">=</span><span class="st">'f1'</span></span>
<span id="cb18-216"><a href="#cb18-216" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb18-217"><a href="#cb18-217" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb18-218"><a href="#cb18-218" aria-hidden="true" tabindex="-1"></a>  results.append(cv_scores)</span>
<span id="cb18-219"><a href="#cb18-219" aria-hidden="true" tabindex="-1"></a>  names.append(name)</span>
<span id="cb18-220"><a href="#cb18-220" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb18-221"><a href="#cb18-221" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="st">'</span><span class="sc">%s</span><span class="st">: </span><span class="sc">%.2f</span><span class="st"> (</span><span class="sc">%.3f</span><span class="st">)'</span> <span class="op">%</span> (name, cv_scores.mean(), cv_scores.std()))</span>
<span id="cb18-222"><a href="#cb18-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-223"><a href="#cb18-223" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-224"><a href="#cb18-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-225"><a href="#cb18-225" aria-hidden="true" tabindex="-1"></a>Although the logistic regression performs slightly better than the random forest, the random forest has higher standard deviation and has more hyperparameters that can be tuned, so it is likely this will model has the highest potential.</span>
<span id="cb18-226"><a href="#cb18-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-227"><a href="#cb18-227" aria-hidden="true" tabindex="-1"></a><span class="fu">### Hyperparameter Tuning</span></span>
<span id="cb18-228"><a href="#cb18-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-229"><a href="#cb18-229" aria-hidden="true" tabindex="-1"></a>Having defined the preprocessing pipeline, we can now train and tune the models. We will use the <span class="in">`GridSearchCV()`</span> function to carry out hyperparameter tuning<span class="ot">[^tuning]</span>, which will search over a grid of hyperparameter values (specified by <span class="in">`params`</span>) to find the best performing model. We will use 5-fold cross-validation to train the models, and will evaluate the models using F1 score and accuracy.</span>
<span id="cb18-230"><a href="#cb18-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-231"><a href="#cb18-231" aria-hidden="true" tabindex="-1"></a>For a more detailed discussion of hyperparameter tuning, and the different methods for tuning in Scikit-learn, the <span class="co">[</span><span class="ot">Tuning the Hyperparameters of an Estimator</span><span class="co">](https://scikit-learn.org/stable/modules/grid_search.html#)</span> section of the Scikit-learn documentation is a good place to start, and the <span class="co">[</span><span class="ot">Hyperparameter Tuning by Grid Search</span><span class="co">](https://inria.github.io/scikit-learn-mooc/python_scripts/parameter_tuning_grid_search.html)</span> section of the Scikit-learn course is an excellent accompaniment.</span>
<span id="cb18-232"><a href="#cb18-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-233"><a href="#cb18-233" aria-hidden="true" tabindex="-1"></a>In addition, the AWS overview of <span class="co">[</span><span class="ot">hyperparameter tuning</span><span class="co">](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html)</span> is a good resource if you are only looking for a brief overview. For an in-depth discussion about how hyperparameter tuning works, including the mathematics behind it, Jeremy Jordan's <span class="co">[</span><span class="ot">Hyperparameter Tuning for Machine Learning Models</span><span class="co">](https://www.jeremyjordan.me/hyperparameter-tuning/)</span> blogpost is thorough but easy to follow.</span>
<span id="cb18-234"><a href="#cb18-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-235"><a href="#cb18-235" aria-hidden="true" tabindex="-1"></a>There are a lot of different Python libraries for hyperparameter tuning, however the most popular libraries that are specifically designed for tuning are <span class="co">[</span><span class="ot">Hyperopt</span><span class="co">](http://hyperopt.github.io/hyperopt/)</span> and <span class="co">[</span><span class="ot">Optuna</span><span class="co">](https://optuna.org/)</span>. Both can be used to tune models built with Scikit-learn (and many other frameworks) and can often produce better results than Scikit-learn's built-in hyperparameter tuning methods. I have had limited experience using Hyperopt, however I have used Optuna often and I would highly recommend it if/when you are ready to move beyond Scikit-learn's options for tuning.</span>
<span id="cb18-236"><a href="#cb18-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-239"><a href="#cb18-239" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-240"><a href="#cb18-240" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> { </span>
<span id="cb18-241"><a href="#cb18-241" aria-hidden="true" tabindex="-1"></a>  <span class="st">'rf__bootstrap'</span>: [<span class="va">True</span>],</span>
<span id="cb18-242"><a href="#cb18-242" aria-hidden="true" tabindex="-1"></a>  <span class="st">'rf__max_depth'</span>: [<span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">30</span>],</span>
<span id="cb18-243"><a href="#cb18-243" aria-hidden="true" tabindex="-1"></a>  <span class="st">"rf__min_samples_leaf"</span> : [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>],</span>
<span id="cb18-244"><a href="#cb18-244" aria-hidden="true" tabindex="-1"></a>  <span class="st">"rf__min_samples_split"</span> : [<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">10</span>],</span>
<span id="cb18-245"><a href="#cb18-245" aria-hidden="true" tabindex="-1"></a>  <span class="st">"rf__n_estimators"</span>: [<span class="dv">100</span>, <span class="dv">250</span>, <span class="dv">500</span>]</span>
<span id="cb18-246"><a href="#cb18-246" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb18-247"><a href="#cb18-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-248"><a href="#cb18-248" aria-hidden="true" tabindex="-1"></a>pipeline <span class="op">=</span> Pipeline([</span>
<span id="cb18-249"><a href="#cb18-249" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'preprocess'</span>, preprocess),</span>
<span id="cb18-250"><a href="#cb18-250" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'rf'</span>, RandomForestClassifier(random_state<span class="op">=</span><span class="dv">123</span>))</span>
<span id="cb18-251"><a href="#cb18-251" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb18-252"><a href="#cb18-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-253"><a href="#cb18-253" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> GridSearchCV(</span>
<span id="cb18-254"><a href="#cb18-254" aria-hidden="true" tabindex="-1"></a>  estimator<span class="op">=</span>pipeline,</span>
<span id="cb18-255"><a href="#cb18-255" aria-hidden="true" tabindex="-1"></a>  param_grid<span class="op">=</span>params,</span>
<span id="cb18-256"><a href="#cb18-256" aria-hidden="true" tabindex="-1"></a>  scoring<span class="op">=</span><span class="st">'f1'</span>,</span>
<span id="cb18-257"><a href="#cb18-257" aria-hidden="true" tabindex="-1"></a>  cv<span class="op">=</span>kf,</span>
<span id="cb18-258"><a href="#cb18-258" aria-hidden="true" tabindex="-1"></a>  verbose<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb18-259"><a href="#cb18-259" aria-hidden="true" tabindex="-1"></a>  refit<span class="op">=</span><span class="va">True</span></span>
<span id="cb18-260"><a href="#cb18-260" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb18-261"><a href="#cb18-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-262"><a href="#cb18-262" aria-hidden="true" tabindex="-1"></a><span class="co"># tune random forest</span></span>
<span id="cb18-263"><a href="#cb18-263" aria-hidden="true" tabindex="-1"></a>tuning_results <span class="op">=</span> clf.fit(X_train, y_train)</span>
<span id="cb18-264"><a href="#cb18-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-265"><a href="#cb18-265" aria-hidden="true" tabindex="-1"></a><span class="co"># get the f1 score for training set</span></span>
<span id="cb18-266"><a href="#cb18-266" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Training F1 Score: </span><span class="sc">%.2f</span><span class="st">'</span> <span class="op">%</span> (tuning_results.best_score_))</span>
<span id="cb18-267"><a href="#cb18-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-268"><a href="#cb18-268" aria-hidden="true" tabindex="-1"></a><span class="co"># get the best performing model on training set</span></span>
<span id="cb18-269"><a href="#cb18-269" aria-hidden="true" tabindex="-1"></a>best_model <span class="op">=</span> tuning_results.best_estimator_</span>
<span id="cb18-270"><a href="#cb18-270" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-271"><a href="#cb18-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-272"><a href="#cb18-272" aria-hidden="true" tabindex="-1"></a><span class="fu">## Model Evaluation</span></span>
<span id="cb18-273"><a href="#cb18-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-276"><a href="#cb18-276" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-277"><a href="#cb18-277" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: evaluation</span></span>
<span id="cb18-278"><a href="#cb18-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-279"><a href="#cb18-279" aria-hidden="true" tabindex="-1"></a><span class="co"># get predictions on holdout set</span></span>
<span id="cb18-280"><a href="#cb18-280" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> best_model.predict(X_test)</span>
<span id="cb18-281"><a href="#cb18-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-282"><a href="#cb18-282" aria-hidden="true" tabindex="-1"></a><span class="co"># get the f1 score for holdout sets</span></span>
<span id="cb18-283"><a href="#cb18-283" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Holdout F1 Score: </span><span class="sc">%.2f</span><span class="st">'</span> <span class="op">%</span> (f1_score(y_test, preds)))</span>
<span id="cb18-284"><a href="#cb18-284" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-285"><a href="#cb18-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-288"><a href="#cb18-288" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-289"><a href="#cb18-289" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: confusion-matrix</span></span>
<span id="cb18-290"><a href="#cb18-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-291"><a href="#cb18-291" aria-hidden="true" tabindex="-1"></a><span class="co"># get confusion matrix</span></span>
<span id="cb18-292"><a href="#cb18-292" aria-hidden="true" tabindex="-1"></a>conf_mat <span class="op">=</span> pd.crosstab(y_test, preds, rownames<span class="op">=</span>[<span class="st">'Actual'</span>], colnames<span class="op">=</span>[<span class="st">'Predicted'</span>])</span>
<span id="cb18-293"><a href="#cb18-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-294"><a href="#cb18-294" aria-hidden="true" tabindex="-1"></a><span class="co"># plot confusion matrix</span></span>
<span id="cb18-295"><a href="#cb18-295" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb18-296"><a href="#cb18-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-297"><a href="#cb18-297" aria-hidden="true" tabindex="-1"></a>sns.heatmap(</span>
<span id="cb18-298"><a href="#cb18-298" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> conf_mat,</span>
<span id="cb18-299"><a href="#cb18-299" aria-hidden="true" tabindex="-1"></a>    annot<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb18-300"><a href="#cb18-300" aria-hidden="true" tabindex="-1"></a>    cmap<span class="op">=</span><span class="st">'Blues'</span>,</span>
<span id="cb18-301"><a href="#cb18-301" aria-hidden="true" tabindex="-1"></a>    fmt<span class="op">=</span><span class="st">'g'</span></span>
<span id="cb18-302"><a href="#cb18-302" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb18-303"><a href="#cb18-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-304"><a href="#cb18-304" aria-hidden="true" tabindex="-1"></a>sns.despine()</span>
<span id="cb18-305"><a href="#cb18-305" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb18-306"><a href="#cb18-306" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-307"><a href="#cb18-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-308"><a href="#cb18-308" aria-hidden="true" tabindex="-1"></a><span class="fu">## Model Interpretation</span></span>
<span id="cb18-309"><a href="#cb18-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-310"><a href="#cb18-310" aria-hidden="true" tabindex="-1"></a>We can compute the features that are most important in predicting heart disease.</span>
<span id="cb18-311"><a href="#cb18-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-314"><a href="#cb18-314" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-315"><a href="#cb18-315" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: feature-importance</span></span>
<span id="cb18-316"><a href="#cb18-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-317"><a href="#cb18-317" aria-hidden="true" tabindex="-1"></a><span class="co"># get feature importance</span></span>
<span id="cb18-318"><a href="#cb18-318" aria-hidden="true" tabindex="-1"></a>feature_importance <span class="op">=</span> best_model.named_steps[<span class="st">'rf'</span>].feature_importances_</span>
<span id="cb18-319"><a href="#cb18-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-320"><a href="#cb18-320" aria-hidden="true" tabindex="-1"></a><span class="co"># get feature names</span></span>
<span id="cb18-321"><a href="#cb18-321" aria-hidden="true" tabindex="-1"></a>feature_names <span class="op">=</span> (</span>
<span id="cb18-322"><a href="#cb18-322" aria-hidden="true" tabindex="-1"></a>    best_model</span>
<span id="cb18-323"><a href="#cb18-323" aria-hidden="true" tabindex="-1"></a>    .named_steps[<span class="st">'preprocess'</span>]</span>
<span id="cb18-324"><a href="#cb18-324" aria-hidden="true" tabindex="-1"></a>    .transformers_[<span class="dv">1</span>][<span class="dv">1</span>]</span>
<span id="cb18-325"><a href="#cb18-325" aria-hidden="true" tabindex="-1"></a>    .named_steps[<span class="st">'one_hot'</span>]</span>
<span id="cb18-326"><a href="#cb18-326" aria-hidden="true" tabindex="-1"></a>    .get_feature_names_out(cat_cols)</span>
<span id="cb18-327"><a href="#cb18-327" aria-hidden="true" tabindex="-1"></a>    .tolist()</span>
<span id="cb18-328"><a href="#cb18-328" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb18-329"><a href="#cb18-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-330"><a href="#cb18-330" aria-hidden="true" tabindex="-1"></a><span class="co"># get feature names</span></span>
<span id="cb18-331"><a href="#cb18-331" aria-hidden="true" tabindex="-1"></a>feature_names <span class="op">=</span> num_cols.tolist() <span class="op">+</span> feature_names</span>
<span id="cb18-332"><a href="#cb18-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-333"><a href="#cb18-333" aria-hidden="true" tabindex="-1"></a><span class="co"># create dataframe</span></span>
<span id="cb18-334"><a href="#cb18-334" aria-hidden="true" tabindex="-1"></a>feat_importance <span class="op">=</span> pd.DataFrame({</span>
<span id="cb18-335"><a href="#cb18-335" aria-hidden="true" tabindex="-1"></a>  <span class="st">'feature'</span>: feature_names, </span>
<span id="cb18-336"><a href="#cb18-336" aria-hidden="true" tabindex="-1"></a>  <span class="st">'importance'</span>: feature_importance</span>
<span id="cb18-337"><a href="#cb18-337" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb18-338"><a href="#cb18-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-339"><a href="#cb18-339" aria-hidden="true" tabindex="-1"></a><span class="co"># plot feature importance</span></span>
<span id="cb18-340"><a href="#cb18-340" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb18-341"><a href="#cb18-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-342"><a href="#cb18-342" aria-hidden="true" tabindex="-1"></a>sns.barplot(</span>
<span id="cb18-343"><a href="#cb18-343" aria-hidden="true" tabindex="-1"></a>    x<span class="op">=</span><span class="st">'importance'</span>,</span>
<span id="cb18-344"><a href="#cb18-344" aria-hidden="true" tabindex="-1"></a>    y<span class="op">=</span><span class="st">'feature'</span>,</span>
<span id="cb18-345"><a href="#cb18-345" aria-hidden="true" tabindex="-1"></a>    data<span class="op">=</span>feat_importance.sort_values(by<span class="op">=</span><span class="st">'importance'</span>, ascending<span class="op">=</span><span class="va">False</span>),</span>
<span id="cb18-346"><a href="#cb18-346" aria-hidden="true" tabindex="-1"></a>    color<span class="op">=</span><span class="st">'#1C355E'</span></span>
<span id="cb18-347"><a href="#cb18-347" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb18-348"><a href="#cb18-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-349"><a href="#cb18-349" aria-hidden="true" tabindex="-1"></a>sns.despine()</span>
<span id="cb18-350"><a href="#cb18-350" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb18-351"><a href="#cb18-351" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-352"><a href="#cb18-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-353"><a href="#cb18-353" aria-hidden="true" tabindex="-1"></a><span class="fu">## Next Steps</span></span>
<span id="cb18-354"><a href="#cb18-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-355"><a href="#cb18-355" aria-hidden="true" tabindex="-1"></a><span class="fu">## Resources</span></span>
<span id="cb18-356"><a href="#cb18-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-357"><a href="#cb18-357" aria-hidden="true" tabindex="-1"></a>There are lots of great (and free) introductory resources for machine learning:</span>
<span id="cb18-358"><a href="#cb18-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-359"><a href="#cb18-359" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">Machine Learning University</span><span class="co">](https://aws.amazon.com/machine-learning/mlu)</span></span>
<span id="cb18-360"><a href="#cb18-360" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">MLU Explain</span><span class="co">](https://mlu-explain.github.io/)</span></span>
<span id="cb18-361"><a href="#cb18-361" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">Machine Learning for Beginners</span><span class="co">](https://microsoft.github.io/ML-For-Beginners/?utm_source=substack&amp;utm_medium=email#/)</span></span>
<span id="cb18-362"><a href="#cb18-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-363"><a href="#cb18-363" aria-hidden="true" tabindex="-1"></a>For a guided video course, Data Talks Club's Machine Learning Zoomcamp (available on <span class="co">[</span><span class="ot">Github</span><span class="co">](https://github.com/alexeygrigorev/mlbookcamp-code/tree/master/course-zoomcamp)</span> and <span class="co">[</span><span class="ot">Youtube</span><span class="co">](https://www.youtube.com/watch?v=MqI8vt3-cag&amp;list=PL3MmuxUbc_hIhxl5Ji8t4O6lPAOpHaCLR)</span>) is well-paced and well-presented, covering a variety of machine learning methods and even covering some of the aspects that introductory course often skip over, like deployment and data engineering principles. However, while the ML Zoomcamp course is intended as an introduction to machine learning, it does assume a certain level of familiarity with programming (the course uses Python) and software engineering. The appendix section of the course is definitely helpful for bridging some of the gaps in the course, but it is still worth being aware of the way the course is structured.</span>
<span id="cb18-364"><a href="#cb18-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-365"><a href="#cb18-365" aria-hidden="true" tabindex="-1"></a>If you are looking for something that goes into greater detail about a wide range of machine learning methods, then there is no better resource than <span class="co">[</span><span class="ot">An Introduction to Statistical Learning</span><span class="co">](https://hastie.su.domains/ISLR2/ISLRv2_website.pdf)</span> (or its accompanying <span class="co">[</span><span class="ot">online course</span><span class="co">](https://www.statlearning.com/online-course)</span>), by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani.</span>
<span id="cb18-366"><a href="#cb18-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-367"><a href="#cb18-367" aria-hidden="true" tabindex="-1"></a>Finally, if you are particularly interested in learning the mathematics that underpins machine learning, I would highly recommend <span class="co">[</span><span class="ot">Mathematics of Machine Learning</span><span class="co">](https://tivadardanka.com/books/mathematics-of-machine-learning)</span>, which is admittedly not free but is very, very good. If you want to learn about the mathematics of machine learning but are not comfortable enough tackling the Mathematics of ML book, the <span class="co">[</span><span class="ot">StatQuest</span><span class="co">](https://www.youtube.com/channel/UCtYLUTtgS3k1Fg4y5tAhLbw)</span> and <span class="co">[</span><span class="ot">3Blue1Brown</span><span class="co">](https://www.youtube.com/c/3blue1brown)</span> Youtube channels are both really accessible and well-presented.</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center"><a href="https://r-data-science-guides.netlify.app"> R Data Science Guides</a> <i class="fa-brands fa-r-project fa-xl" aria-label="r-project"></i></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>



</body></html>